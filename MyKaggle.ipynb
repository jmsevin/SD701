{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cover Type Prediction of Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "completeData = pd.read_csv(\"train-data.csv\")\n",
    "submissionData = pd.read_csv(\"test-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   1       2596      51      3                               258   \n",
       "1   2       2590      56      2                               212   \n",
       "2   3       2804     139      9                               268   \n",
       "3   4       2785     155     18                               242   \n",
       "4   5       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm     ...      Soil_Type32  \\\n",
       "0            221             232            148     ...                0   \n",
       "1            220             235            151     ...                0   \n",
       "2            234             238            135     ...                0   \n",
       "3            238             238            122     ...                0   \n",
       "4            220             234            150     ...                0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0           5  \n",
       "1            0            0            0           5  \n",
       "2            0            0            0           2  \n",
       "3            0            0            0           2  \n",
       "4            0            0            0           5  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data visualization in Trifacta software gave me some insights : *Cover_Type* distribution is balanced in complete data and there's no apparent missing values. Some *Hillshade_3pm* values look suspicious, but their impact is unsignificant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = completeData\n",
    "idComplete = df.pop('Id')\n",
    "df2 = submissionData\n",
    "idSubmission = df2.pop('Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoir overfitting, it's often useful to reduce manually the number of features, based on data examination. *Soil_Type(s)* values are very sparse and we know that we can merge them, based on climatic zones and geologic zones (cf. Study Code USFS ELU Code Description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def climatic_zones(df):\n",
    "  # Merging \"Lower montane dry\" soil types\n",
    "  df[\"Lower_montane_dry\"] = df.Soil_Type1 + df.Soil_Type2 + df.Soil_Type3 + df.Soil_Type4 + df.Soil_Type5 + df.Soil_Type6\n",
    "  # Merging \"Lower montane\" soil types\n",
    "  df[\"Lower_montane\"] = df.Soil_Type7 + df.Soil_Type8\n",
    "  # Merging \"Montane dry\" soil types\n",
    "  df[\"Montane_dry\"] = df.Soil_Type9    \n",
    "  # Merging \"Montane\" soil types\n",
    "  df[\"Montane\"] = df.Soil_Type10 + df.Soil_Type11 + df.Soil_Type12 + df.Soil_Type13\n",
    "  # Merging \"Montane dry and montane\" soil types\n",
    "  df[\"Montane_dry_and_montane\"] = df.Soil_Type14 + df.Soil_Type15    \n",
    "  # Merging \"Montane and subalpine\" soil types\n",
    "  df[\"Montane_and_subalpine\"] = df.Soil_Type16 + df.Soil_Type17 + df.Soil_Type18    \n",
    "  # Merging \"Subalpine\" soil types\n",
    "  df[\"Subalpine\"] = df.Soil_Type19 + df.Soil_Type20 + df.Soil_Type21 + df.Soil_Type22 + df.Soil_Type23 + df.Soil_Type24 + df.Soil_Type25 + df.Soil_Type26 + df.Soil_Type27 + df.Soil_Type28 + df.Soil_Type29 + df.Soil_Type30 + df.Soil_Type31 + df.Soil_Type32 + df.Soil_Type33 + df.Soil_Type34    \n",
    "  # Merging \"Alpine\" soil types\n",
    "  df[\"Alpine\"] = df.Soil_Type35 + df.Soil_Type36 + df.Soil_Type37 + df.Soil_Type38 + df.Soil_Type39 + df.Soil_Type40\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geologic_zones(df):\n",
    "  # Merging \"Igneous and metamorphic\" soil types\n",
    "  df[\"Igneous_and_metamorphic\"] = df.Soil_Type1 + df.Soil_Type2 + df.Soil_Type3 + df.Soil_Type4 + df.Soil_Type5 + df.Soil_Type6 + df.Soil_Type10 + df.Soil_Type11 + df.Soil_Type12 + df.Soil_Type13 + df.Soil_Type18 + df.Soil_Type24 + df.Soil_Type25 + df.Soil_Type26 + df.Soil_Type27 + df.Soil_Type28 + df.Soil_Type29 + df.Soil_Type30 + df.Soil_Type31 + df.Soil_Type32 + df.Soil_Type33 + df.Soil_Type34 + df.Soil_Type35 + df.Soil_Type36 + df.Soil_Type37 + df.Soil_Type38 + df.Soil_Type39 + df.Soil_Type40\n",
    "  # Merging \"Mixed sedimentary\" soil types\n",
    "  df[\"Mixed_sedimentary\"] = df.Soil_Type7 + df.Soil_Type8\n",
    "  # Merging \"Glacial\" soil types\n",
    "  df[\"Glacial\"] = df.Soil_Type9 + df.Soil_Type22 + df.Soil_Type23\n",
    "  # Merging \"Alluvium\" soil types\n",
    "  df[\"Alluvium\"] = df.Soil_Type14 + df.Soil_Type15 + df.Soil_Type16 + df.Soil_Type17 + df.Soil_Type19 + df.Soil_Type20 + df.Soil_Type21\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we extracted all information from *Soil_Type(s)* values, we can remove all these columns now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_soil_cols(df):\n",
    "    df.drop(['Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4',\n",
    "        'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
    "        'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
    "        'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
    "        'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
    "        'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
    "        'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
    "        'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
    "        'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
    "        'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we're merging both horizontal and vertical distances to hydrology into one column only, using Pythagorean theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_to_hydrology(df):\n",
    "    df[\"Distance_To_Hydrology\"] = np.sqrt(np.multiply(df.Horizontal_Distance_To_Hydrology,df.Horizontal_Distance_To_Hydrology) + np.multiply(df.Vertical_Distance_To_Hydrology,df.Vertical_Distance_To_Hydrology))\n",
    "    df.drop(['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As *Aspect* feature is an angle, we need to work on it so that hidden similarity between distant values like 10 and 350 is reflected. In order to do that, we'll replace *Aspect* values by their sinus and cosinus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_aspect(df):\n",
    "    df[\"Sin\"] = np.sin(df[\"Aspect\"] * np.pi / 180)\n",
    "    df[\"Cos\"] = np.cos(df[\"Aspect\"] * np.pi / 180)    \n",
    "    df.drop(['Aspect'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = climatic_zones(df)\n",
    "df = geologic_zones(df)\n",
    "df = remove_soil_cols(df)\n",
    "df = distance_to_hydrology(df)\n",
    "df = new_aspect(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Slope', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Cover_Type', 'Lower_montane_dry', 'Lower_montane', 'Montane_dry',\n",
       "       'Montane', 'Montane_dry_and_montane', 'Montane_and_subalpine',\n",
       "       'Subalpine', 'Alpine', 'Igneous_and_metamorphic', 'Mixed_sedimentary',\n",
       "       'Glacial', 'Alluvium', 'Distance_To_Hydrology', 'Sin', 'Cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.pop('Cover_Type').values\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split the complete data in order to get a train set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started to test classifiers using the simplest one: Logistic Regression. This gave me a first reference score.\n",
    "\n",
    "Then, I tested a few others and compared their scores; best results on the test set were the ones using Random Forest and SVC classifiers.\n",
    "\n",
    "As a next step, I tested both classifiers in a pipeline including some feature selection. SVC gave the best score, so I kept this classifier and finally performed an iterative exhaustive search on C and gamma parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('fs', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0....,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__gamma': [0.09, 0.1, 0.11], 'clf__C': [125, 150, 175]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#clf = linear_model.LogisticRegression()\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "#clf = SVC()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('fs', SelectFromModel(ExtraTreesClassifier(n_estimators=100))),\n",
    "  ('clf', SVC())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'clf__gamma': [0.09, 0.1, 0.11],\n",
    "    'clf__C': [125, 150, 175],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params)\n",
    "gs.fit(X, y)\n",
    "\n",
    "#clf.fit(X_train, y_train)\n",
    "#score = clf.score(X_test, y_test)\n",
    "#print(score)\n",
    "    \n",
    "#pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 125, 'clf__gamma': 0.1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model was ready, I applied it to submission data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = climatic_zones(df2)\n",
    "df2 = geologic_zones(df2)\n",
    "df2 = remove_soil_cols(df2)\n",
    "df2 = distance_to_hydrology(df2)\n",
    "df2 = new_aspect(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_kaggle = df2.values\n",
    "X_kaggle = scaler.transform(X_kaggle)\n",
    "#y_kaggle = pipe.predict(X_kaggle)\n",
    "y_kaggle = gs.best_estimator_.predict(X_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15121</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15122</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15123</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15125</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cover_Type\n",
       "Id               \n",
       "15121           7\n",
       "15122           7\n",
       "15123           7\n",
       "15124           7\n",
       "15125           7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = pd.DataFrame(y_kaggle, idSubmission, columns=['Cover_Type'])\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_kaggle.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Et voilà! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Nota Bene: Through repeated submissions on Kaggle, I quickly noticed that *Cover_Type* distribution in submission data wasn't balanced at all though it was perfectly balanced in complete data that we used to train our models. However, I decided not to include this information in my process (for example, I could have used the class_weight parameter in the SVC to reflect the correct distribution of submission data) as I consider it as data leakage.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
